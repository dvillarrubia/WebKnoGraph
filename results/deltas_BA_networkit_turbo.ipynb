{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYgtCa_8srDm"
   },
   "outputs": [],
   "source": [
    "# NetworKit-based PageRank Simulation - Clean Version\n",
    "# Calculates Mean Delta %, Max Delta %, Min Delta % only\n",
    "\n",
    "# === INSTALLATION ===\n",
    "!pip install networkit pandas numpy matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkit as nk\n",
    "import time\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "BASELINE_PATH = \"/content/drive/MyDrive/WebKnoGraph/results/link_graph_edges.csv\"\n",
    "COMPARISON_FOLDER = \"/content/drive/MyDrive/WebKnoGraph/results/expert_led/low_batches/\"\n",
    "\n",
    "NUM_SIMULATIONS = 100\n",
    "MIN_CONNECTIONS = 5\n",
    "MAX_CONNECTIONS = 50\n",
    "TOTAL_NODES_WWW = 100000\n",
    "EDGES_PER_NEW_NODE = 2\n",
    "PAGERANK_TOLERANCE = 1e-6\n",
    "\n",
    "_www_graph_cache = None\n",
    "\n",
    "\n",
    "def mount_google_drive():\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "\n",
    "        drive.mount(\"/content/drive\")\n",
    "        print(\"Google Drive mounted successfully!\")\n",
    "        return True\n",
    "    except:\n",
    "        print(\"Not in Colab - skipping drive mount\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def load_graph_from_csv_networkit(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, usecols=[\"FROM\", \"TO\"])\n",
    "        df = df.dropna()\n",
    "        df[\"FROM\"] = df[\"FROM\"].astype(str)\n",
    "        df[\"TO\"] = df[\"TO\"].astype(str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "    from_urls = df[\"FROM\"].values\n",
    "    to_urls = df[\"TO\"].values\n",
    "\n",
    "    if len(from_urls) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    all_urls = np.unique(np.concatenate([from_urls, to_urls]))\n",
    "    url_to_idx = {url: i for i, url in enumerate(all_urls)}\n",
    "\n",
    "    g = nk.Graph(n=len(all_urls), weighted=False, directed=True)\n",
    "    for src_url, tgt_url in zip(from_urls, to_urls):\n",
    "        g.addEdge(url_to_idx[src_url], url_to_idx[tgt_url])\n",
    "\n",
    "    return g, all_urls, url_to_idx\n",
    "\n",
    "\n",
    "def create_www_graph_networkit(n_nodes, m_edges, seed=42):\n",
    "    global _www_graph_cache\n",
    "\n",
    "    cache_key = (n_nodes, m_edges, seed)\n",
    "    if _www_graph_cache is not None and _www_graph_cache[0] == cache_key:\n",
    "        cached_graph = _www_graph_cache[1]\n",
    "        new_graph = nk.Graph(\n",
    "            n=cached_graph.numberOfNodes(), weighted=False, directed=True\n",
    "        )\n",
    "        for u, v in cached_graph.iterEdges():\n",
    "            new_graph.addEdge(u, v)\n",
    "        return new_graph\n",
    "\n",
    "    nk.setSeed(seed, False)\n",
    "    generator = nk.generators.BarabasiAlbertGenerator(\n",
    "        k=m_edges, nMax=n_nodes, n0=m_edges\n",
    "    )\n",
    "    www_graph = generator.generate()\n",
    "\n",
    "    cached_graph = nk.Graph(n=www_graph.numberOfNodes(), weighted=False, directed=True)\n",
    "    for u, v in www_graph.iterEdges():\n",
    "        cached_graph.addEdge(u, v)\n",
    "    _www_graph_cache = (cache_key, cached_graph)\n",
    "    return www_graph\n",
    "\n",
    "\n",
    "def process_configuration_networkit(www_graph, kalicube_edges, kalicube_nodes):\n",
    "    kalicube_offset = www_graph.numberOfNodes()\n",
    "    n_kalicube = len(kalicube_nodes)\n",
    "\n",
    "    merged_graph = nk.Graph(n=www_graph.numberOfNodes(), weighted=False, directed=True)\n",
    "    for u, v in www_graph.iterEdges():\n",
    "        merged_graph.addEdge(u, v)\n",
    "\n",
    "    for _ in range(n_kalicube):\n",
    "        merged_graph.addNode()\n",
    "\n",
    "    if kalicube_edges:\n",
    "        for src, tgt in kalicube_edges:\n",
    "            merged_graph.addEdge(src + kalicube_offset, tgt + kalicube_offset)\n",
    "\n",
    "    n_www_sample = min(MIN_CONNECTIONS, TOTAL_NODES_WWW)\n",
    "    n_kalicube_sample = min(MIN_CONNECTIONS, len(kalicube_nodes))\n",
    "\n",
    "    www_nodes_sample = np.random.choice(\n",
    "        TOTAL_NODES_WWW, size=n_www_sample, replace=False\n",
    "    )\n",
    "    kalicube_indices = np.random.choice(\n",
    "        len(kalicube_nodes), size=n_kalicube_sample, replace=False\n",
    "    )\n",
    "\n",
    "    for www_node_id, kalicube_idx in zip(www_nodes_sample, kalicube_indices):\n",
    "        merged_graph.addEdge(www_node_id, kalicube_idx + kalicube_offset)\n",
    "\n",
    "    pagerank_algo = nk.centrality.PageRank(\n",
    "        merged_graph, damp=0.85, tol=PAGERANK_TOLERANCE\n",
    "    )\n",
    "    pagerank_algo.run()\n",
    "    pagerank_scores = pagerank_algo.scores()\n",
    "\n",
    "    pagerank_dict = {}\n",
    "    for i, url in enumerate(kalicube_nodes):\n",
    "        pagerank_dict[url] = pagerank_scores[i + kalicube_offset]\n",
    "\n",
    "    return pagerank_dict\n",
    "\n",
    "\n",
    "def run_single_simulation(sim_id, old_edges, new_edges, old_nodes, new_nodes):\n",
    "    sim_seed = 42 + sim_id\n",
    "    np.random.seed(sim_seed)\n",
    "    random.seed(sim_seed)\n",
    "\n",
    "    www_graph = create_www_graph_networkit(\n",
    "        TOTAL_NODES_WWW, EDGES_PER_NEW_NODE, sim_seed\n",
    "    )\n",
    "\n",
    "    pagerank_old = process_configuration_networkit(www_graph, old_edges, old_nodes)\n",
    "    pagerank_new = process_configuration_networkit(www_graph, new_edges, new_nodes)\n",
    "\n",
    "    # Get common URLs\n",
    "    common_urls = set(pagerank_old.keys()) & set(pagerank_new.keys())\n",
    "    if not common_urls:\n",
    "        return None\n",
    "\n",
    "    # Calculate percentage changes\n",
    "    delta_pcts = []\n",
    "    for url in common_urls:\n",
    "        old_val = pagerank_old[url]\n",
    "        new_val = pagerank_new[url]\n",
    "        delta = new_val - old_val\n",
    "        delta_pct = (delta / max(old_val, 1e-10)) * 100\n",
    "        delta_pcts.append(delta_pct)\n",
    "\n",
    "    delta_pcts = np.array(delta_pcts)\n",
    "\n",
    "    return {\n",
    "        \"Simulation\": sim_id + 1,\n",
    "        \"Mean_Delta_%\": np.mean(delta_pcts),\n",
    "        \"Max_Delta_%\": np.max(delta_pcts),\n",
    "        \"Min_Delta_%\": np.min(delta_pcts),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_comparison(baseline_data, comparison_file, output_folder):\n",
    "    comparison_name = comparison_file.stem\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Starting: {comparison_name}\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load comparison graph\n",
    "    g_old, nodes_old, _ = baseline_data\n",
    "    g_new, nodes_new, _ = load_graph_from_csv_networkit(comparison_file)\n",
    "\n",
    "    if g_new is None:\n",
    "        print(f\"Failed to load {comparison_file.name}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Baseline: {g_old.numberOfNodes():,} nodes, {g_old.numberOfEdges():,} edges\")\n",
    "    print(\n",
    "        f\"Comparison: {g_new.numberOfNodes():,} nodes, {g_new.numberOfEdges():,} edges\"\n",
    "    )\n",
    "\n",
    "    # Convert to edge lists\n",
    "    old_edges = [(u, v) for u, v in g_old.iterEdges()]\n",
    "    new_edges = [(u, v) for u, v in g_new.iterEdges()]\n",
    "\n",
    "    del g_new\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"\\nRunning {NUM_SIMULATIONS} simulations...\")\n",
    "\n",
    "    # Run simulations\n",
    "    results = []\n",
    "    for i in range(NUM_SIMULATIONS):\n",
    "        result = run_single_simulation(i, old_edges, new_edges, nodes_old, nodes_new)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Completed {i + 1}/{NUM_SIMULATIONS}\")\n",
    "\n",
    "    if not results:\n",
    "        print(\"No valid results\")\n",
    "        return None\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save\n",
    "    safe_name = comparison_name.replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "    summary_path = output_folder / f\"{safe_name}_summary.csv\"\n",
    "    results_df.to_csv(summary_path, index=False)\n",
    "\n",
    "    # Statistics\n",
    "    mean_val = results_df[\"Mean_Delta_%\"].mean()\n",
    "    max_val = results_df[\"Max_Delta_%\"].mean()\n",
    "    min_val = results_df[\"Min_Delta_%\"].mean()\n",
    "\n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Mean Delta: {mean_val:.2f}%\")\n",
    "    print(f\"  Max Delta: {max_val:.2f}%\")\n",
    "    print(f\"  Min Delta: {min_val:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    print(f\"\\nValidation:\")\n",
    "    v1 = max_val >= mean_val\n",
    "    v2 = mean_val >= min_val\n",
    "    v3 = max_val >= min_val\n",
    "    v4 = min_val <= mean_val <= max_val\n",
    "\n",
    "    print(f\"  Max >= Mean: {'PASS' if v1 else 'FAIL'}\")\n",
    "    print(f\"  Mean >= Min: {'PASS' if v2 else 'FAIL'}\")\n",
    "    print(f\"  Max >= Min: {'PASS' if v3 else 'FAIL'}\")\n",
    "    print(f\"  Min <= Mean <= Max: {'PASS' if v4 else 'FAIL'}\")\n",
    "\n",
    "    all_pass = v1 and v2 and v3 and v4\n",
    "    print(f\"  Overall: {'ALL PASSED' if all_pass else 'SOME FAILED'}\")\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"\\nCompleted in {duration:.1f}s\")\n",
    "\n",
    "    return {\n",
    "        \"name\": comparison_name,\n",
    "        \"duration\": duration,\n",
    "        \"mean\": mean_val,\n",
    "        \"max\": max_val,\n",
    "        \"min\": min_val,\n",
    "        \"valid\": all_pass,\n",
    "    }\n",
    "\n",
    "\n",
    "def create_master_summary(all_results, output_folder):\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"MASTER SUMMARY\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "\n",
    "    data = []\n",
    "    for r in all_results:\n",
    "        if r:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"Comparison\": r[\"name\"],\n",
    "                    \"Mean_Delta_%\": r[\"mean\"],\n",
    "                    \"Max_Delta_%\": r[\"max\"],\n",
    "                    \"Min_Delta_%\": r[\"min\"],\n",
    "                    \"Valid\": r[\"valid\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    if not data:\n",
    "        print(\"No valid results\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(\"Mean_Delta_%\", ascending=False)\n",
    "\n",
    "    df.to_csv(output_folder / \"MASTER_SUMMARY.csv\", index=False)\n",
    "\n",
    "    print(\"\\nRankings:\")\n",
    "    for _, row in df.iterrows():\n",
    "        symbol = \"+\" if row[\"Mean_Delta_%\"] > 0 else \"-\"\n",
    "        valid = \"[OK]\" if row[\"Valid\"] else \"[!]\"\n",
    "        print(f\"  {valid} {symbol} {row['Comparison']}: {row['Mean_Delta_%']:.2f}%\")\n",
    "\n",
    "    valid_count = df[\"Valid\"].sum()\n",
    "    print(f\"\\nValid: {valid_count}/{len(df)}\")\n",
    "\n",
    "\n",
    "def calculate_final_averages(all_results, output_folder):\n",
    "    \"\"\"\n",
    "    Calculate final averages across all comparison files for the entire strategy.\n",
    "\n",
    "    Args:\n",
    "        all_results: List of result dictionaries from run_comparison()\n",
    "        output_folder: Path object for saving results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"FINAL STRATEGY AVERAGES\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "\n",
    "    # Filter out None results\n",
    "    valid_results = [r for r in all_results if r is not None]\n",
    "\n",
    "    if not valid_results:\n",
    "        print(\"No valid results to calculate averages\")\n",
    "        return None\n",
    "\n",
    "    # Extract metrics\n",
    "    mean_deltas = [r[\"mean\"] for r in valid_results]\n",
    "    max_deltas = [r[\"max\"] for r in valid_results]\n",
    "    min_deltas = [r[\"min\"] for r in valid_results]\n",
    "\n",
    "    # Calculate final averages\n",
    "    final_mean_avg = np.mean(mean_deltas)\n",
    "    final_max_avg = np.mean(max_deltas)\n",
    "    final_min_avg = np.mean(min_deltas)\n",
    "\n",
    "    # Overall average (grand mean)\n",
    "    overall_avg = np.mean([final_mean_avg, final_max_avg, final_min_avg])\n",
    "\n",
    "    # Calculate standard deviations\n",
    "    mean_std = np.std(mean_deltas)\n",
    "    max_std = np.std(max_deltas)\n",
    "    min_std = np.std(min_deltas)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nComparison Files Processed: {len(valid_results)}\")\n",
    "    print(f\"Total Simulations: {len(valid_results) * NUM_SIMULATIONS}\")\n",
    "    print(f\"\\nFinal Averages:\")\n",
    "    print(f\"  Average Mean Delta: {final_mean_avg:.2f}% (±{mean_std:.2f})\")\n",
    "    print(f\"  Average Max Delta:  {final_max_avg:.2f}% (±{max_std:.2f})\")\n",
    "    print(f\"  Average Min Delta:  {final_min_avg:.2f}% (±{min_std:.2f})\")\n",
    "    print(f\"\\nOverall Strategy Average: {overall_avg:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    print(f\"\\nValidation:\")\n",
    "    v1 = final_max_avg >= final_mean_avg\n",
    "    v2 = final_mean_avg >= final_min_avg\n",
    "    v3 = final_max_avg >= final_min_avg\n",
    "\n",
    "    print(f\"  Max >= Mean: {'PASS' if v1 else 'FAIL'}\")\n",
    "    print(f\"  Mean >= Min: {'PASS' if v2 else 'FAIL'}\")\n",
    "    print(f\"  Max >= Min: {'PASS' if v3 else 'FAIL'}\")\n",
    "\n",
    "    all_pass = v1 and v2 and v3\n",
    "    print(f\"  Overall: {'ALL PASSED' if all_pass else 'SOME FAILED'}\")\n",
    "\n",
    "    # Save to CSV\n",
    "    final_summary = {\n",
    "        \"Metric\": [\n",
    "            \"Average_Mean_Delta_%\",\n",
    "            \"Average_Max_Delta_%\",\n",
    "            \"Average_Min_Delta_%\",\n",
    "            \"Overall_Strategy_Average_%\",\n",
    "        ],\n",
    "        \"Value\": [final_mean_avg, final_max_avg, final_min_avg, overall_avg],\n",
    "        \"Std_Dev\": [mean_std, max_std, min_std, np.nan],\n",
    "    }\n",
    "\n",
    "    final_df = pd.DataFrame(final_summary)\n",
    "    final_path = output_folder / \"FINAL_STRATEGY_AVERAGES.csv\"\n",
    "    final_df.to_csv(final_path, index=False)\n",
    "\n",
    "    print(f\"\\nSaved to: {final_path.name}\")\n",
    "\n",
    "    return {\n",
    "        \"final_mean_avg\": final_mean_avg,\n",
    "        \"final_max_avg\": final_max_avg,\n",
    "        \"final_min_avg\": final_min_avg,\n",
    "        \"overall_avg\": overall_avg,\n",
    "        \"mean_std\": mean_std,\n",
    "        \"max_std\": max_std,\n",
    "        \"min_std\": min_std,\n",
    "        \"num_comparisons\": len(valid_results),\n",
    "        \"valid\": all_pass,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"NetworKit PageRank Simulation\")\n",
    "    print(f\"NetworKit version: {nk.__version__}\")\n",
    "\n",
    "    mount_google_drive()\n",
    "\n",
    "    # Verify baseline\n",
    "    baseline_path = Path(BASELINE_PATH)\n",
    "    if not baseline_path.exists():\n",
    "        print(f\"Baseline not found: {BASELINE_PATH}\")\n",
    "        exit(1)\n",
    "\n",
    "    print(f\"\\nBaseline: {baseline_path.name}\")\n",
    "\n",
    "    # Find comparison files\n",
    "    comparison_folder = Path(COMPARISON_FOLDER)\n",
    "    comparison_files = list(comparison_folder.glob(\"*.csv\"))\n",
    "\n",
    "    if not comparison_files:\n",
    "        print(f\"No CSV files in: {COMPARISON_FOLDER}\")\n",
    "        exit(1)\n",
    "\n",
    "    print(f\"Found {len(comparison_files)} comparison files\")\n",
    "\n",
    "    # Create output folder\n",
    "    output_folder = comparison_folder / \"simulation_results\"\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    # Load baseline\n",
    "    print(\"\\nLoading baseline...\")\n",
    "    baseline_data = load_graph_from_csv_networkit(baseline_path)\n",
    "    if baseline_data[0] is None:\n",
    "        print(\"Failed to load baseline\")\n",
    "        exit(1)\n",
    "\n",
    "    g, nodes, _ = baseline_data\n",
    "    print(f\"Loaded: {g.numberOfNodes():,} nodes, {g.numberOfEdges():,} edges\")\n",
    "\n",
    "    # Run comparisons\n",
    "    all_results = []\n",
    "    for i, comp_file in enumerate(comparison_files, 1):\n",
    "        print(f\"\\n\\n{'#' * 70}\")\n",
    "        print(f\"Comparison {i}/{len(comparison_files)}\")\n",
    "        print(f\"{'#' * 70}\")\n",
    "\n",
    "        result = run_comparison(baseline_data, comp_file, output_folder)\n",
    "        all_results.append(result)\n",
    "\n",
    "        _www_graph_cache = None\n",
    "        gc.collect()\n",
    "\n",
    "    # Create master summary\n",
    "    create_master_summary(all_results, output_folder)\n",
    "\n",
    "    # Calculate final averages\n",
    "    final_results = calculate_final_averages(all_results, output_folder)\n",
    "\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(\"COMPLETE\")\n",
    "    print(f\"Results: {output_folder}\")\n",
    "    print(f\"{'=' * 70}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}