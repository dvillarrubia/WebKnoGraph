{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yM9jrJJD6aQo"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_p3euqGm6bHd"
   },
   "source": [
    "# pip install -r requirements.txt first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pa14it5t9RHz"
   },
   "outputs": [],
   "source": [
    "# File: notebooks/link_prediction_ui.ipynb - Cell 1\n",
    "\n",
    "# Installing necessary packages\n",
    "# !pip install -q torch torch-geometric pandas duckdb pyarrow networkx gradio -q\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import gradio as gr\n",
    "import io\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Suppress common warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", category=FutureWarning, module=\"huggingface_hub.file_download\"\n",
    ")\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = \"/content/drive/My Drive/WebKnoGraph\"  # Explicitly set\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Project root added to sys.path: {project_root}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"sys.path: {sys.path}\")\n",
    "\n",
    "# Google Colab Drive Mount\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    if not os.path.exists(\"/content/drive/My Drive\"):\n",
    "        drive.mount(\"/content/drive/\")\n",
    "        print(\"Google Drive mounted successfully.\")\n",
    "    else:\n",
    "        print(\"Google Drive already mounted.\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Google Colab environment. Skipping Google Drive mount.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error mounting Google Drive: {e}\")\n",
    "\n",
    "# Import from your refactored backend and shared modules\n",
    "from src.backend.config.link_prediction_config import LinkPredictionConfig\n",
    "from src.backend.data.graph_dataloader import GraphDataLoader\n",
    "from src.backend.data.graph_processor import GraphDataProcessor\n",
    "from src.backend.models.graph_models import GraphSAGEModel\n",
    "from src.backend.utils.url_processing import URLProcessor\n",
    "from src.backend.services.graph_training_service import LinkPredictionTrainer\n",
    "from src.backend.services.recommendation_engine import RecommendationEngine\n",
    "from src.shared.logging_config import ConsoleAndGradioLogger\n",
    "\n",
    "print(\"All modules imported successfully!\")\n",
    "\n",
    "\n",
    "def get_all_nodes_for_dropdown():\n",
    "    \"\"\"\n",
    "    Dynamically loads node URLs from the saved model metadata (artifacts).\n",
    "    If artifacts are not found, it returns a message indicating training is needed.\n",
    "    \"\"\"\n",
    "    log_stream_dummy = io.StringIO()\n",
    "    logger_dummy = ConsoleAndGradioLogger(\n",
    "        log_stream_dummy, logger_name=\"DropdownLogger\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        config = LinkPredictionConfig()\n",
    "        model_metadata_path = config.node_mapping_path\n",
    "\n",
    "        if os.path.exists(model_metadata_path):\n",
    "            with open(model_metadata_path, \"r\") as f:\n",
    "                model_metadata = json.load(f)\n",
    "            if \"url_to_idx\" in model_metadata:\n",
    "                url_to_idx = model_metadata[\"url_to_idx\"]\n",
    "                return sorted(list(url_to_idx.keys()))\n",
    "            else:\n",
    "                logger_dummy.error(\"Model metadata is incomplete (missing url_to_idx).\")\n",
    "                return [\"Error: Model metadata is incomplete (missing url_to_idx).\"]\n",
    "        else:\n",
    "            logger_dummy.info(\n",
    "                \"Model artifacts not found. Run training first to generate artifacts.\"\n",
    "            )\n",
    "            return [\"Run training first to generate artifacts.\"]\n",
    "    except Exception as e:\n",
    "        logger_dummy.exception(f\"Could not load URLs for dropdown from artifacts: {e}\")\n",
    "        return [\n",
    "            f\"Could not load URLs from artifacts: {e}. Ensure Google Drive is mounted and artifacts exist.\"\n",
    "        ]\n",
    "\n",
    "\n",
    "def run_training_pipeline(\n",
    "    csv_path,\n",
    "    embeddings_path,\n",
    "    hidden_channels,\n",
    "    out_channels,\n",
    "    lr,\n",
    "    epochs,\n",
    "    progress=gr.Progress(track_tqdm=True),\n",
    "):\n",
    "    log_stream = io.StringIO()\n",
    "    logger = ConsoleAndGradioLogger(\n",
    "        log_stream, logger_name=\"LinkPredictionTrainerLogger\"\n",
    "    )\n",
    "\n",
    "    dropdown_choices = get_all_nodes_for_dropdown()\n",
    "\n",
    "    try:\n",
    "        yield \"Step 1/5: Initializing...\", log_stream.getvalue(), None, dropdown_choices\n",
    "        config = LinkPredictionConfig(\n",
    "            edge_csv_path=csv_path,\n",
    "            embeddings_dir_path=embeddings_path,\n",
    "            hidden_channels=int(hidden_channels),\n",
    "            out_channels=int(out_channels),\n",
    "            learning_rate=lr,\n",
    "            epochs=int(epochs),\n",
    "        )\n",
    "        os.makedirs(config.output_dir, exist_ok=True)\n",
    "\n",
    "        all_artifacts_exist = (\n",
    "            os.path.exists(config.model_state_path)\n",
    "            and os.path.exists(config.node_embeddings_path)\n",
    "            and os.path.exists(config.node_mapping_path)\n",
    "            and os.path.exists(config.edge_index_path)\n",
    "        )\n",
    "\n",
    "        if all_artifacts_exist:\n",
    "            status_message = (\n",
    "                \"âœ… All artifacts already exist. Skipping training and saving.\"\n",
    "            )\n",
    "            logger.info(status_message)\n",
    "            dropdown_choices = get_all_nodes_for_dropdown()\n",
    "            yield (\n",
    "                status_message,\n",
    "                log_stream.getvalue(),\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"Message\": [\n",
    "                            \"Artifacts found. You can now use the recommendation tab.\"\n",
    "                        ]\n",
    "                    },\n",
    "                    columns=[\"Message\"],\n",
    "                ),\n",
    "                dropdown_choices,\n",
    "            )\n",
    "            return\n",
    "\n",
    "        yield (\n",
    "            \"Step 2/5: Loading & processing data...\",\n",
    "            log_stream.getvalue(),\n",
    "            None,\n",
    "            dropdown_choices,\n",
    "        )\n",
    "        loader = GraphDataLoader(config, logger)\n",
    "        node_features_df, edge_list_df = loader.load_data()\n",
    "        processor = GraphDataProcessor(logger)\n",
    "        data, url_to_idx = processor.process(node_features_df, edge_list_df)\n",
    "\n",
    "        yield (\n",
    "            \"Step 3/5: Initializing model...\",\n",
    "            log_stream.getvalue(),\n",
    "            None,\n",
    "            dropdown_choices,\n",
    "        )\n",
    "        model = GraphSAGEModel(\n",
    "            in_channels=data.num_node_features,\n",
    "            hidden_channels=config.hidden_channels,\n",
    "            out_channels=config.out_channels,\n",
    "        )\n",
    "        trainer = LinkPredictionTrainer(model, data, config, logger)\n",
    "\n",
    "        yield (\n",
    "            \"Step 4/5: Training model...\",\n",
    "            log_stream.getvalue(),\n",
    "            None,\n",
    "            dropdown_choices,\n",
    "        )\n",
    "        for epoch, loss in progress.tqdm(\n",
    "            trainer.train(), total=config.epochs, desc=\"Training Model\"\n",
    "        ):\n",
    "            if epoch % 10 == 0 or epoch == 1:\n",
    "                logger.info(f\"Epoch {epoch}/{config.epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "        yield (\n",
    "            \"Step 5/5: Evaluating and saving artifacts... \",\n",
    "            log_stream.getvalue(),\n",
    "            None,\n",
    "            dropdown_choices,\n",
    "        )\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            final_node_embeddings = model(data.x, data.edge_index)\n",
    "\n",
    "        logger.info(f\"Saving model metadata to {config.node_mapping_path}\")\n",
    "        model_metadata = {\n",
    "            \"url_to_idx\": url_to_idx,\n",
    "            \"in_channels\": data.num_node_features,\n",
    "            \"hidden_channels\": config.hidden_channels,\n",
    "            \"out_channels\": config.out_channels,\n",
    "        }\n",
    "        with open(config.node_mapping_path, \"w\") as f:\n",
    "            json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "        logger.info(f\"Saving model weights to {config.model_state_path}\")\n",
    "        torch.save(model.state_dict(), config.model_state_path)\n",
    "        logger.info(f\"Saving final node embeddings to {config.node_embeddings_path}\")\n",
    "        torch.save(final_node_embeddings, config.node_embeddings_path)\n",
    "        logger.info(f\"Saving edge index to {config.edge_index_path}\")\n",
    "        torch.save(data.edge_index, config.edge_index_path)\n",
    "\n",
    "        final_status = \"âœ… Pipeline Finished Successfully!\"\n",
    "        logger.info(final_status)\n",
    "        dropdown_choices = get_all_nodes_for_dropdown()\n",
    "        yield (\n",
    "            final_status,\n",
    "            log_stream.getvalue(),\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Message\": [\n",
    "                        \"Artifacts saved successfully. You can now use the recommendation tab.\"\n",
    "                    ]\n",
    "                },\n",
    "                columns=[\"Message\"],\n",
    "            ),\n",
    "            dropdown_choices,\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"A critical error occurred: {e}\")\n",
    "        dropdown_choices = get_all_nodes_for_dropdown()\n",
    "        yield (\n",
    "            \"Pipeline Failed\",\n",
    "            log_stream.getvalue(),\n",
    "            pd.DataFrame({\"Error\": [str(e)]}),\n",
    "            dropdown_choices,\n",
    "        )\n",
    "\n",
    "\n",
    "def run_recommendation_interface(\n",
    "    source_url: str, min_depth: int, max_depth: int, folder_path: str\n",
    "):\n",
    "    placeholder_message = \"Run training first to generate artifacts.\"\n",
    "    if source_url == placeholder_message or source_url.startswith(\"Error:\"):\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"Error\": [\n",
    "                    \"Please train the model first and select a valid URL from the dropdown. Current selection is a placeholder or error message.\"\n",
    "                ]\n",
    "            },\n",
    "            columns=[\"Error\"],\n",
    "        ), f\"Error: Selected source URL is a placeholder or invalid: '{source_url}'\"\n",
    "\n",
    "    if not source_url:\n",
    "        return None, \"Please select a source URL from the dropdown.\"\n",
    "    log_stream = io.StringIO()\n",
    "    logger = ConsoleAndGradioLogger(\n",
    "        log_stream, logger_name=\"RecommendationEngineLogger\"\n",
    "    )\n",
    "    config = LinkPredictionConfig()\n",
    "    url_processor = URLProcessor()\n",
    "    engine = RecommendationEngine(config, logger, url_processor)\n",
    "\n",
    "    if min_depth is None:\n",
    "        min_depth = 0\n",
    "    if max_depth is None:\n",
    "        max_depth = 100\n",
    "    if min_depth > max_depth:\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"Error\": [\n",
    "                    \"Minimum folder depth cannot be greater than maximum folder depth.\"\n",
    "                ]\n",
    "            },\n",
    "            columns=[\"Error\"],\n",
    "        ), \"Error: Minimum folder depth cannot be greater than maximum folder depth.\"\n",
    "\n",
    "    # Pass all three filters to the backend\n",
    "    recommendations_df, error_msg = engine.get_recommendations(\n",
    "        source_url,\n",
    "        top_n=20,\n",
    "        min_folder_depth=min_depth,\n",
    "        max_folder_depth=max_depth,\n",
    "        folder_path_filter=folder_path,\n",
    "    )\n",
    "    if error_msg:\n",
    "        logger.error(error_msg)\n",
    "        return pd.DataFrame(\n",
    "            {\"Error\": [error_msg]}, columns=[\"Error\"]\n",
    "        ), log_stream.getvalue()\n",
    "\n",
    "    if recommendations_df is None or recommendations_df.empty:\n",
    "        logger.info(\"No recommendations found matching the specified filters.\")\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"Message\": [\n",
    "                    \"No recommendations found matching the specified filters. Try adjusting your depth range or path filter.\"\n",
    "                ]\n",
    "            },\n",
    "            columns=[\"Message\"],\n",
    "        ), log_stream.getvalue()\n",
    "\n",
    "    return recommendations_df, log_stream.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6Z5SPrn9UAp"
   },
   "outputs": [],
   "source": [
    "# File: notebooks/link_prediction_ui.ipynb - Cell 2\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# ðŸ“ˆ GNN Link Prediction & Recommendation Engine\")\n",
    "    gr.Markdown(\n",
    "        \"First, use the 'Train Model' tab to process your data. Then, use the 'Get Link Recommendations' tab to get predictions for new, non-existent links.\"\n",
    "    )\n",
    "\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Train Model\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"## 1. Configuration\")\n",
    "                    with gr.Accordion(\"Data Paths\", open=True):\n",
    "                        edge_csv_path_input = gr.Textbox(\n",
    "                            label=\"Edge List CSV Path\",\n",
    "                            value=LinkPredictionConfig.edge_csv_path,\n",
    "                        )\n",
    "                        embeddings_dir_path_input = gr.Textbox(\n",
    "                            label=\"Embeddings Directory Path\",\n",
    "                            value=LinkPredictionConfig.embeddings_dir_path,\n",
    "                        )\n",
    "                    with gr.Accordion(\"Model Hyperparameters\", open=True):\n",
    "                        hidden_channels_input = gr.Number(\n",
    "                            label=\"Hidden Channels\",\n",
    "                            value=LinkPredictionConfig.hidden_channels,\n",
    "                        )\n",
    "                        out_channels_input = gr.Number(\n",
    "                            label=\"Output Embedding Size\",\n",
    "                            value=LinkPredictionConfig.out_channels,\n",
    "                        )\n",
    "                    with gr.Accordion(\"Training Parameters\", open=True):\n",
    "                        learning_rate_input = gr.Number(\n",
    "                            label=\"Learning Rate\",\n",
    "                            value=LinkPredictionConfig.learning_rate,\n",
    "                        )\n",
    "                        epochs_input = gr.Number(\n",
    "                            label=\"Training Epochs\", value=LinkPredictionConfig.epochs\n",
    "                        )\n",
    "                    start_button = gr.Button(\n",
    "                        \"Train Link Prediction Model\", variant=\"primary\"\n",
    "                    )\n",
    "                with gr.Column(scale=2):\n",
    "                    gr.Markdown(\"## 2. Training Status\")\n",
    "                    train_status_output = gr.Textbox(\n",
    "                        label=\"Current Status\", interactive=False\n",
    "                    )\n",
    "                    train_log_output = gr.Textbox(\n",
    "                        label=\"Pipeline Logs\", interactive=False, lines=15\n",
    "                    )\n",
    "                    train_results_output = gr.DataFrame(\n",
    "                        label=\"Training Completion Status\"\n",
    "                    )\n",
    "\n",
    "        with gr.TabItem(\"Get Link Recommendations\"):\n",
    "            gr.Markdown(\"## 1. Select a Source Page & Filters\")\n",
    "            gr.Markdown(\n",
    "                \"Choose a URL and the model will recommend top pages it should link to. (You must train the model on the tab to the left first).\"\n",
    "            )\n",
    "            with gr.Row():\n",
    "                source_url_dropdown = gr.Dropdown(\n",
    "                    label=\"Source URL\",\n",
    "                    choices=get_all_nodes_for_dropdown(),\n",
    "                    interactive=True,\n",
    "                )\n",
    "            with gr.Row():\n",
    "                min_folder_depth_input = gr.Number(\n",
    "                    label=\"Minimum Folder Depth\", value=0, precision=0\n",
    "                )\n",
    "                max_folder_depth_input = gr.Number(\n",
    "                    label=\"Maximum Folder Depth\", value=100, precision=0\n",
    "                )\n",
    "                folder_path_input = gr.Textbox(\n",
    "                    label=\"Filter by URL Folder Path\",\n",
    "                    placeholder=\"e.g., https://example.com/blog\",\n",
    "                )\n",
    "\n",
    "            recommend_button = gr.Button(\"Get Recommendations\", variant=\"primary\")\n",
    "            gr.Markdown(\"## 2. Results: High-Potential Missing Links\")\n",
    "            recommend_results_output = gr.DataFrame(\n",
    "                label=\"Top Link Recommendations\",\n",
    "                headers=[\"RECOMMENDED_URL\", \"SCORE\", \"FOLDER_DEPTH\"],\n",
    "            )\n",
    "            recommend_log_output = gr.Textbox(label=\"Logs\", interactive=False, lines=4)\n",
    "\n",
    "    start_button.click(\n",
    "        fn=run_training_pipeline,\n",
    "        inputs=[\n",
    "            edge_csv_path_input,\n",
    "            embeddings_dir_path_input,\n",
    "            hidden_channels_input,\n",
    "            out_channels_input,\n",
    "            learning_rate_input,\n",
    "            epochs_input,\n",
    "        ],\n",
    "        outputs=[\n",
    "            train_status_output,\n",
    "            train_log_output,\n",
    "            train_results_output,\n",
    "            source_url_dropdown,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    recommend_button.click(\n",
    "        fn=run_recommendation_interface,\n",
    "        inputs=[\n",
    "            source_url_dropdown,\n",
    "            min_folder_depth_input,\n",
    "            max_folder_depth_input,\n",
    "            folder_path_input,\n",
    "        ],\n",
    "        outputs=[recommend_results_output, recommend_log_output],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ael-N9Tn9YU4"
   },
   "outputs": [],
   "source": [
    "# File: notebooks/link_prediction_ui.ipynb - Cell 3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "\n",
    "        if not os.path.exists(\"/content/drive/My Drive\"):\n",
    "            drive.mount(\"/content/drive/\")\n",
    "            print(\"Google Drive mounted successfully.\")\n",
    "        else:\n",
    "            print(\"Google Drive already mounted.\")\n",
    "\n",
    "        demo.launch(debug=True, share=True)\n",
    "    except ImportError:\n",
    "        # If not in a Colab environment, try to launch without the drive mount.\n",
    "        print(\"Not in Google Colab environment. Launching Gradio demo locally.\")\n",
    "        demo.launch(debug=True, share=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not launch Gradio demo in this environment: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
